<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WiSDoM: Interpretable Weakly-Supervised Learning Through Kernel Density Matrices - Sebastian Medina</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="A mathematical deep dive into WiSDoM, our PLOS ONE paper introducing kernel density matrices for interpretable weakly-supervised learning in digital pathology.">
    <meta name="author" content="Sebastian Medina">
    <meta name="keywords" content="kernel density matrices, weakly-supervised learning, interpretable AI, digital pathology, prostate cancer, Gleason grading, WiSDoM, deep learning">

    <!-- Highwire Press / Google Scholar Meta Tags -->
    <meta name="citation_title" content="Interpretable weakly-supervised learning through kernel density matrices: A digital pathology use case">
    <meta name="citation_author" content="Medina, Sebastian">
    <meta name="citation_author" content="Romero, Eduardo">
    <meta name="citation_author" content="Cruz-Roa, Angel">
    <meta name="citation_author" content="Gonzalez, Fabio A.">
    <meta name="citation_publication_date" content="2025">
    <meta name="citation_journal_title" content="PLOS ONE">
    <meta name="citation_issn" content="1932-6203">
    <meta name="citation_doi" content="10.1371/journal.pone.0335826">
    <meta name="citation_pdf_url" content="https://doi.org/10.1371/journal.pone.0335826">

    <!-- Dublin Core Meta Tags for Altmetric -->
    <meta name="DC.identifier" content="doi:10.1371/journal.pone.0335826">
    <meta name="DC.title" content="Interpretable weakly-supervised learning through kernel density matrices: A digital pathology use case">
    <meta name="DC.creator" content="Medina, Sebastian">
    <meta name="DC.date" content="2025">
    <meta name="DC.publisher" content="PLOS ONE">
    <meta name="DC.type" content="article">

    <!-- Open Graph Meta Tags for Social Sharing -->
    <meta property="og:title" content="WiSDoM: Interpretable Weakly-Supervised Learning Through Kernel Density Matrices">
    <meta property="og:description" content="Mathematical deep dive into kernel density matrices for interpretable medical image classification.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://srmedinac.github.io/blog/wisdom-kernel-density-matrices.html">
    <meta property="og:site_name" content="Sebastian Medina">
    <meta property="article:published_time" content="2025-01-06">
    <meta property="article:author" content="Sebastian Medina">
    <meta property="article:tag" content="kernel methods">
    <meta property="article:tag" content="weakly-supervised learning">
    <meta property="article:tag" content="interpretability">

    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="WiSDoM: Kernel Density Matrices for Interpretable Medical AI">
    <meta name="twitter:description" content="Mathematical deep dive into our PLOS ONE paper on interpretable weakly-supervised learning.">

    <!-- Canonical URL -->
    <link rel="canonical" href="https://srmedinac.github.io/blog/wisdom-kernel-density-matrices.html">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">

    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- MathJax for LaTeX Equations -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Structured Data for Search Engines and Altmetric -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BlogPosting",
      "headline": "WiSDoM: Interpretable Weakly-Supervised Learning Through Kernel Density Matrices",
      "author": {
        "@type": "Person",
        "name": "Sebastian Medina",
        "url": "https://srmedinac.github.io",
        "affiliation": {
          "@type": "Organization",
          "name": "Georgia Institute of Technology and Emory University"
        }
      },
      "datePublished": "2025-01-06",
      "description": "A mathematical deep dive into WiSDoM, introducing kernel density matrices for interpretable weakly-supervised learning in digital pathology.",
      "keywords": ["kernel density matrices", "weakly-supervised learning", "interpretability", "digital pathology", "prostate cancer"],
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://srmedinac.github.io/blog/wisdom-kernel-density-matrices.html"
      },
      "about": {
        "@type": "ScholarlyArticle",
        "@id": "https://doi.org/10.1371/journal.pone.0335826",
        "name": "Interpretable weakly-supervised learning through kernel density matrices: A digital pathology use case",
        "headline": "Interpretable weakly-supervised learning through kernel density matrices: A digital pathology use case",
        "author": [
          {"@type": "Person", "name": "Sebastian Medina"},
          {"@type": "Person", "name": "Eduardo Romero"},
          {"@type": "Person", "name": "Angel Cruz-Roa"},
          {"@type": "Person", "name": "Fabio A. Gonzalez"}
        ],
        "datePublished": "2025",
        "isPartOf": {
          "@type": "PublicationIssue",
          "isPartOf": {
            "@type": "Periodical",
            "name": "PLOS ONE",
            "issn": "1932-6203",
            "publisher": {
              "@type": "Organization",
              "name": "Public Library of Science"
            }
          }
        },
        "url": "https://doi.org/10.1371/journal.pone.0335826",
        "sameAs": [
          "https://doi.org/10.1371/journal.pone.0335826",
          "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0335826"
        ],
        "identifier": {
          "@type": "PropertyValue",
          "propertyID": "doi",
          "value": "10.1371/journal.pone.0335826"
        }
      }
    }
    </script>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">Sebastian Medina</div>
            <ul class="nav-menu">
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../publications.html">Publications</a></li>
                <li><a href="../index.html#blog">Blog</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <div class="container">
        <article class="blog-post">
            <a href="../index.html#blog" class="back-link">
                <i class="fas fa-arrow-left"></i> Back to Blog
            </a>

            <div class="blog-post-header">
                <h1>WiSDoM: Interpretable Weakly-Supervised Learning Through Kernel Density Matrices</h1>
                <div class="blog-post-meta">
                    <span><i class="fas fa-calendar"></i> January 2025</span>
                    <span><i class="fas fa-tag"></i> kernel methods, weakly-supervised learning, interpretability, digital pathology</span>
                </div>
            </div>

            <div class="blog-post-content">
                <p><strong>Authors:</strong> Sebastian Medina, Eduardo Romero, Angel Cruz-Roa, Fabio A. Gonzalez</p>
                <p><strong>Published in:</strong> PLOS ONE (2025) | <a href="https://doi.org/10.1371/journal.pone.0335826" target="_blank">doi:10.1371/journal.pone.0335826</a></p>

                <!-- IMAGE PLACEHOLDER: Graphical Abstract -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 1:</strong> WiSDoM architecture overview showing the flow from input patches through the encoder, attention mechanism, and kernel density matrix inference to produce interpretable predictions with uncertainty estimates.
                    </p>
                </div>

                <h2>The Problem</h2>

                <p>
                    Classification models in digital pathology operate under two paradigms. Fully-supervised approaches require detailed annotations at the pixel or patch level, which are costly to obtain and require significant pathologist time. Weakly-supervised approaches use only slide-level labels but typically function as black boxes, providing predictions without explanations.
                </p>

                <p>
                    A third limitation cuts across both paradigms: most models output point predictions without quantifying their own uncertainty. A model that predicts "Gleason 4" with 95% confidence and one that predicts "Gleason 4" with 55% confidence produce identical outputs, despite the second case warranting additional review.
                </p>

                <p>
                    WiSDoM addresses all three limitations through a single mathematical framework based on kernel density matrices.
                </p>

                <h2>Core Intuition: Predictions as Probability Distributions</h2>

                <p>
                    Standard classifiers map inputs to discrete labels. WiSDoM instead maps inputs to <em>probability distributions over labels</em>. This distinction has practical consequences.
                </p>

                <p>
                    Consider classifying a tissue patch as Gleason pattern 3, 4, or 5. A standard softmax classifier outputs probabilities like [0.7, 0.2, 0.1]. These probabilities reflect the model's confidence given its training, but they don't capture the inherent ambiguity in the input. A patch at the boundary between Gleason 3 and 4 should produce a distribution centered between the two grades with high variance, not an overconfident prediction for one or the other.
                </p>

                <p>
                    WiSDoM achieves this by representing both inputs and outputs as density matrices, mathematical objects that encode probability distributions. The model learns a joint distribution over input features and output labels, then performs probabilistic inference to transform new inputs into output distributions.
                </p>

                <!-- IMAGE PLACEHOLDER: Intuition diagram -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 2:</strong> Comparison of standard classification (left) versus WiSDoM (right). Standard classifiers output point predictions. WiSDoM outputs full probability distributions with expected values and variances, enabling uncertainty-aware predictions.
                    </p>
                </div>

                <h2>Density Matrices: The Mathematical Foundation</h2>

                <p>
                    Density matrices originate from quantum mechanics, where they describe statistical mixtures of quantum states. For our purposes, they provide a convenient formalism for representing and manipulating probability distributions over feature spaces.
                </p>

                <p>
                    A density matrix $\rho$ represents a mixture of states $|\psi_i\rangle$ with probabilities $p_i$:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\rho = \sum_{i=1}^{N} p_i |\psi_i\rangle\langle\psi_i|$$
                </p>

                <p>
                    <strong>Intuition:</strong> Think of each $|\psi_i\rangle$ as a prototype example and $p_i$ as its importance weight. The density matrix encodes which prototypes are relevant and how much each contributes to the overall distribution.
                </p>

                <p>
                    Given a new query state $|\psi\rangle$, we compute the probability of observing it under the distribution encoded by $\rho$:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$p(|\psi\rangle | \rho) = \langle\psi|\rho|\psi\rangle = \sum_{i=1}^{N} p_i |\langle\psi|\psi_i\rangle|^2$$
                </p>

                <p>
                    <strong>Intuition:</strong> The probability depends on how similar the query $|\psi\rangle$ is to each prototype $|\psi_i\rangle$, measured by the inner product $\langle\psi|\psi_i\rangle$. Similar inputs to similar prototypes yield high probabilities. This is analogous to kernel density estimation, where the density at a point depends on its distance to the training examples.
                </p>

                <h2>Kernel Density Matrices</h2>

                <p>
                    To apply density matrices to machine learning, we need to connect them to feature spaces. A Kernel Density Matrix (KDM) is defined by three components:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\rho = (C, \mathbf{p}, k_\theta)$$
                </p>

                <ul>
                    <li>$C = \{x^{(1)}, \ldots, x^{(m)}\}$: a set of prototype examples from the input space</li>
                    <li>$\mathbf{p} = (p_1, \ldots, p_m)$: mixture weights satisfying $\sum_i p_i = 1$</li>
                    <li>$k_\theta$: a kernel function measuring similarity between inputs</li>
                </ul>

                <p>
                    The kernel function implicitly maps inputs to a high-dimensional feature space (the reproducing kernel Hilbert space) where inner products become kernel evaluations. For a normalized kernel with $k(x, x) = 1$, we have:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$|\langle\psi|\psi_i\rangle|^2 = k_\theta^2(x, x^{(i)})$$
                </p>

                <p>
                    The projection function then measures how well a new input aligns with the distribution:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$f_\rho(x) = \sum_{i=1}^{m} p_i \cdot k_\theta^2(x, x^{(i)})$$
                </p>

                <p>
                    <strong>Intuition:</strong> This is a weighted sum of squared kernel similarities. Inputs near high-weight prototypes receive high probability mass. The squared kernel ensures non-negativity required for proper probability distributions.
                </p>

                <!-- IMAGE PLACEHOLDER: KDM visualization -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 3:</strong> Kernel density matrix visualization. Left: prototypes in feature space with their weights (circle sizes). Right: the resulting probability density function, showing higher density near heavily weighted prototypes.
                    </p>
                </div>

                <h2>Inference: From Inputs to Label Distributions</h2>

                <p>
                    The key to WiSDoM is using KDMs for probabilistic inference. We maintain a joint KDM $\rho_{x',y'}$ over input-output pairs learned from training data. Given a new input, we compute a distribution over possible outputs.
                </p>

                <p>
                    The joint KDM stores $m'$ prototype pairs $(x'^{(i)}, y'^{(i)})$ with weights $p'_i$:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\rho_{x',y'} = \left(\{(x'^{(i)}, y'^{(i)})\}_{i=1}^{m'}, (p'_i)_{i=1}^{m'}, k_\mathbb{X} \otimes k_\mathbb{Y}\right)$$
                </p>

                <p>
                    For a new input represented by its own KDM $\rho_x$, inference produces output probabilities:
                </p>

                <p style="text-align: center; margin: 1.5rem 0; background-color: #f8f9fa; padding: 1rem; border-radius: 8px;">
                    $$p''_i = \sum_{\ell=1}^{m} \frac{p_\ell \cdot p'_i \cdot k_\mathbb{X}^2(x^{(\ell)}, x'^{(i)})}{\sum_{j=1}^{m'} p'_j \cdot k_\mathbb{X}^2(x^{(\ell)}, x'^{(j)})}$$
                </p>

                <p>
                    <strong>Intuition:</strong> This equation computes how much each training prototype $(x'^{(i)}, y'^{(i)})$ contributes to the prediction. Prototypes with input features similar to the query (high $k_\mathbb{X}^2(x^{(\ell)}, x'^{(i)})$) contribute more. The denominator normalizes these contributions to form a proper probability distribution.
                </p>

                <p>
                    The output KDM $\rho_y$ then provides both a predicted label (via expected value) and uncertainty (via variance):
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\mathbb{E}[\hat{y}] = \sum_{j=1}^{m'} p''_j \cdot y'_j \qquad \text{Var}[\hat{y}] = \sum_{j=1}^{m'} p''_j \cdot (y'_j)^2 - \left(\mathbb{E}[\hat{y}]\right)^2$$
                </p>

                <p>
                    High variance indicates the input is similar to prototypes with different labels, signaling ambiguity in the prediction.
                </p>

                <!-- IMAGE PLACEHOLDER: Inference diagram -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 4:</strong> Inference procedure. A new input (star) is compared to all prototypes in the joint KDM. Prototypes with similar input features contribute their labels to the output distribution, weighted by kernel similarity.
                    </p>
                </div>

                <h2>From Fully-Supervised to Weakly-Supervised</h2>

                <h3>Fully-Supervised Classification</h3>

                <p>
                    For patch-level classification with individual patch labels, the input KDM has a single component:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\rho_x = (\{z\}, (1), k_\mathbb{X})$$
                </p>

                <p>
                    where $z = Z(x)$ is the CNN-encoded feature vector of the input patch. The inference equation simplifies accordingly, comparing this single encoded patch to all prototypes.
                </p>

                <h3>Weakly-Supervised Classification with Attention</h3>

                <p>
                    For whole-slide classification with only slide-level labels, we face the multiple instance learning problem: a slide is a "bag" of patches, and we know the slide's label but not individual patch labels.
                </p>

                <p>
                    WiSDoM handles this by constructing an input KDM with multiple components, one per patch. The mixture weights $p_i$ are learned through an attention mechanism:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\rho_x = \left(\{z_j\}_{j=1}^{k}, (z^{\text{attn}}_j)_{j=1}^{k}, k_\mathbb{X}\right)$$
                </p>

                <p>
                    The attention mechanism combines local and global information. Each patch first computes a local context vector:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$z^{\text{local}}_j = \text{MLP}_1(x_j)$$
                </p>

                <p>
                    A global context aggregates across all patches:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$z^{\text{global}} = \frac{1}{k} \sum_{j=1}^{k} z^{\text{local}}_j$$
                </p>

                <p>
                    Attention weights emerge from comparing local and global contexts:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$z^{\text{attn}}_j = \text{Softmax}\left(\text{MLP}_2(z^{\text{local}}_j, z^{\text{global}})\right)$$
                </p>

                <p>
                    <strong>Intuition:</strong> Patches whose local context differs significantly from the global average receive higher attention. In prostate cancer grading, tumor regions stand out from the predominantly stromal background, naturally receiving higher weights. These weights then determine each patch's contribution to the slide-level prediction through the KDM framework.
                </p>

                <!-- IMAGE PLACEHOLDER: Attention mechanism -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 5:</strong> Local-global attention mechanism. Left: patches from a whole-slide image. Center: local context vectors compared to the global average. Right: resulting attention weights highlighting diagnostically relevant regions.
                    </p>
                </div>

                <h2>Ordinal Regression for Cancer Grading</h2>

                <p>
                    Cancer grades are ordinal: Gleason 3 &lt; 4 &lt; 5 represents increasing severity. Standard classification treats grades as unrelated categories, ignoring this structure. A model that confuses Gleason 3 with Gleason 5 incurs the same loss as one confusing Gleason 3 with Gleason 4, despite the former being a more serious error.
                </p>

                <p>
                    WiSDoM addresses this through ordinal regression. Labels are converted to continuous values on $[0, 1]$:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$y_{\text{ordinal}} = \frac{y_{\text{categorical}}}{N_{\text{labels}}}$$
                </p>

                <p>
                    The loss function penalizes both prediction error and uncertainty:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} \left(\mathbb{E}[\hat{y}]_i - y_i\right)^2 + \alpha \cdot \text{Var}[\hat{y}]_i$$
                </p>

                <p>
                    <strong>Intuition:</strong> The MSE term encourages accurate predictions. The variance term $\alpha \cdot \text{Var}[\hat{y}]$ encourages confident predictions by penalizing high uncertainty. The hyperparameter $\alpha$ controls this tradeoff. During inference, we can filter out high-variance predictions for expert review.
                </p>

                <h2>Interpretability Through Prototypes</h2>

                <p>
                    A key advantage of the KDM framework is interpretability. The joint KDM $\rho_{x',y'}$ stores explicit prototypes that drive predictions. When the model predicts a label, we can identify which prototypes contributed most by examining the kernel similarities.
                </p>

                <p>
                    For a prediction on input $x$, the contribution of prototype $i$ is proportional to:
                </p>

                <p style="text-align: center; margin: 1.5rem 0;">
                    $$\text{contribution}_i \propto p'_i \cdot k_\mathbb{X}^2(x, x'^{(i)})$$
                </p>

                <p>
                    The top-contributing prototypes provide example-based explanations: "This patch was classified as Gleason 4 because it resembles these training examples, which were labeled Gleason 4."
                </p>

                <!-- IMAGE PLACEHOLDER: Prototype examples -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 6:</strong> Prototype-based interpretability. For a query patch (left), the model identifies the most similar prototypes from each Gleason grade (right), providing example-based explanations for its prediction.
                    </p>
                </div>

                <p>
                    In experiments, pathologists assessed 36 randomly selected prototypes without seeing their labels. Agreement between pathologist labels and model-assigned prototype labels reached Cohen's $\kappa = 0.88$, indicating the learned representations correspond to recognized histological patterns.
                </p>

                <h2>Uncertainty Quantification</h2>

                <p>
                    The variance of the output distribution provides a principled uncertainty estimate. High variance occurs when the input is similar to prototypes with different labels, indicating the model lacks confidence.
                </p>

                <!-- IMAGE PLACEHOLDER: Uncertainty visualization -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 7:</strong> Uncertainty maps. Left: whole-slide image with prediction heatmap. Right: corresponding uncertainty map showing regions where the model is less confident, often at grade boundaries or in ambiguous tissue.
                    </p>
                </div>

                <p>
                    Filtering predictions by variance threshold improves performance. On the PANDA dataset, removing high-variance predictions ($\sigma^2 \geq 0.05$) improved Cohen's $\kappa$ from 0.900 to 0.930. This suggests the model correctly identifies difficult cases that would benefit from pathologist review.
                </p>

                <h2>Experimental Results</h2>

                <p>
                    WiSDoM was evaluated on the PANDA Challenge dataset containing 10,616 prostate biopsies from two institutions with ISUP grade group labels.
                </p>

                <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                    <thead>
                        <tr style="background-color: var(--bg-light);">
                            <th style="border: 1px solid var(--border-color); padding: 0.75rem; text-align: left;">Task</th>
                            <th style="border: 1px solid var(--border-color); padding: 0.75rem; text-align: left;">Cohen's $\kappa$</th>
                            <th style="border: 1px solid var(--border-color); padding: 0.75rem; text-align: left;">Accuracy</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">Patch-level Gleason Classification</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">0.896</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">90.1%</td>
                        </tr>
                        <tr style="background-color: var(--bg-light);">
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">Patch-level Ordinal Regression</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">0.906</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">89.0%</td>
                        </tr>
                        <tr>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">Whole-Slide ISUP Grading</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">0.900</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">66.0%</td>
                        </tr>
                        <tr style="background-color: var(--bg-light);">
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;">With Variance Filtering ($\sigma^2 < 0.05$)</td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;"><strong>0.930</strong></td>
                            <td style="border: 1px solid var(--border-color); padding: 0.75rem;"><strong>73.0%</strong></td>
                        </tr>
                    </tbody>
                </table>

                <p>
                    The $\kappa = 0.930$ with variance filtering exceeds the top PANDA Challenge submission ($\kappa = 0.921$), which used ensemble methods. WiSDoM achieves this with a single model while providing interpretability and uncertainty estimates unavailable in the competition winners.
                </p>

                <!-- IMAGE PLACEHOLDER: t-SNE of learned prototypes -->
                <div style="background-color: #f0f0f0; border: 2px dashed #ccc; padding: 2rem; margin: 2rem 0; text-align: center; border-radius: 8px;">
                    <p style="color: #666; font-style: italic; margin: 0;">
                        <strong>Figure 8:</strong> t-SNE visualization of learned prototypes colored by Gleason grade. The embedding shows clear clustering by grade with ordinal structure preserved: adjacent grades cluster nearby while distant grades separate.
                    </p>
                </div>

                <h2>Limitations and Future Directions</h2>

                <p>
                    Several limitations warrant consideration. The computational cost of kernel evaluations scales with the number of prototypes, though the 216 prototypes used here add negligible overhead compared to the CNN backbone. The choice of kernel function (RBF in our experiments) affects performance, and kernel selection remains an area for further study. Finally, while WiSDoM provides uncertainty estimates, these are not calibrated probability statements; calibration techniques could improve the reliability of uncertainty quantification.
                </p>

                <h2>Code and Data</h2>

                <p>
                    Implementation: <a href="https://github.com/srmedinac/WiSDoM" target="_blank">github.com/srmedinac/WiSDoM</a>
                </p>

                <p>
                    Dataset: <a href="https://www.kaggle.com/competitions/prostate-cancer-grade-assessment" target="_blank">PANDA Challenge on Kaggle</a>
                </p>

                <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border-color);">

                <p><strong>Reference:</strong></p>
                <p>
                    Medina S, Romero E, Cruz-Roa A, Gonzalez FA. Interpretable weakly-supervised learning through kernel density matrices: A digital pathology use case. <em>PLoS One</em>. 2025;20(11):e0335826.
                    <a href="https://doi.org/10.1371/journal.pone.0335826" target="_blank">doi:10.1371/journal.pone.0335826</a>
                </p>
            </div>
        </article>
    </div>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Sebastian Medina. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
